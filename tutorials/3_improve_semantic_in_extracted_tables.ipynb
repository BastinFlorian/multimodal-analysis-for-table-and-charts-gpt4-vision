{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve semantic search with table summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to summarize extracted tables to provide a better similarity score for semantic search. \n",
    "\n",
    "We will use:\n",
    "- the extracted HTML table\n",
    "- the | separated table (less tokens)\n",
    "\n",
    "We will compare the question similarity score for both tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian.bastin/miniconda3/envs/.multi_venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from config.llm import GPT_4\n",
    "from config.embedings import AZURE_ADA_002_EMBEDDINGS\n",
    "from utils import html_table_to_pipe_table, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = \"\"\"\n",
    "    <table>\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th>Provider</th>\n",
    "                <th>Model</th>\n",
    "                <th>input price per 1k Token</th>\n",
    "                <th>output price per 1K Token</th>\n",
    "                <th>input price per 1M Token</th>\n",
    "                <th>output price per 1M Token</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        <tbody>\n",
    "            <tr>\n",
    "                <td>(Azure) OpenAI</td>\n",
    "                <td>GPT-4 (8K)</td>\n",
    "                <td>$0.03000</td>\n",
    "                <td>$0.06000</td>\n",
    "                <td>$30.00</td>\n",
    "                <td>$60.00</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td></td>\n",
    "                <td>GPT-4 Turbo</td>\n",
    "                <td>$0.01000</td>\n",
    "                <td>$0.03000</td>\n",
    "                <td>$10.00</td>\n",
    "                <td>$30.00</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td></td>\n",
    "                <td>GPT-3.5-turbo</td>\n",
    "                <td>$0.00050</td>\n",
    "                <td>$0.00150</td>\n",
    "                <td>$0.50</td>\n",
    "                <td>$1.50</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>Google Vertex AI<br>1 token ~= 4 chars</td>\n",
    "                <td>Gemini Pro</td>\n",
    "                <td>$0.00100</td>\n",
    "                <td>$0.00200</td>\n",
    "                <td>$1.00</td>\n",
    "                <td>$2.00</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td></td>\n",
    "                <td>PaLM 2</td>\n",
    "                <td>$0.00200</td>\n",
    "                <td>$0.00200</td>\n",
    "                <td>$2.00</td>\n",
    "                <td>$2.00</td>\n",
    "            </tr>\n",
    "        </tbody>\n",
    "    </table>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider | Model | input price per 1k Token | output price per 1K Token | input price per 1M Token | output price per 1M Token\n",
      "------------------------------------------------------------------------------------------------------------------------------\n",
      "(Azure) OpenAI | GPT-4 (8K) | $0.03000 | $0.06000 | $30.00 | $60.00\n",
      "nan | GPT-4 Turbo | $0.01000 | $0.03000 | $10.00 | $30.00\n",
      "nan | GPT-3.5-turbo | $0.00050 | $0.00150 | $0.50 | $1.50\n",
      "Google Vertex AI 1 token ~= 4 chars | Gemini Pro | $0.00100 | $0.00200 | $1.00 | $2.00\n",
      "nan | PaLM 2 | $0.00200 | $0.00200 | $2.00 | $2.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe_table = html_table_to_pipe_table(html_table)\n",
    "print(pipe_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00203144090557718,\n",
       " 0.007626032678073521,\n",
       " 0.0007786905269745078,\n",
       " -0.01533421359754763,\n",
       " -0.005866705610244608]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_embeddings = AZURE_ADA_002_EMBEDDINGS.embed_documents([html_table])[0]\n",
    "html_embeddings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01585491179451621,\n",
       " -0.014221546164635206,\n",
       " 0.005311958929257258,\n",
       " -0.0089764706313801,\n",
       " -0.0020293865710770877]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_embeddings = AZURE_ADA_002_EMBEDDINGS.embed_documents([pipe_table])[0]\n",
    "pipe_embeddings[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_question = \"Can you sort the Azure and GCP LLMs by their costs per thousand tokens?\"\n",
    "en_question_embeddings = AZURE_ADA_002_EMBEDDINGS.embed_documents([en_question])[0]\n",
    "\n",
    "fr_question = \"Peux-tu trier les LLM des cloud Azure et GCP selon leur coÃ»ts par milliers de token ?\"\n",
    "fr_question_embeddings = AZURE_ADA_002_EMBEDDINGS.embed_documents([fr_question])[\n",
    "    0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's study the similarity between the question (english and french) and the table content (html and pipe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English question\n",
      "Cosine similarity between html table and question: 0.8224233060059337\n",
      "Cosine similarity between pipe table and question: 0.8110228519118848\n",
      "\n",
      "French question:\n",
      "Cosine similarity between html table and question: 0.7645364328228879\n",
      "Cosine similarity between pipe table and question: 0.7492020302722854\n"
     ]
    }
   ],
   "source": [
    "# English question\n",
    "print(\"English question\")\n",
    "print(\"Cosine similarity between html table and question:\",\n",
    "      cosine_similarity(html_embeddings, en_question_embeddings))\n",
    "print(\"Cosine similarity between pipe table and question:\",\n",
    "      cosine_similarity(pipe_embeddings, en_question_embeddings))\n",
    "\n",
    "# French question\n",
    "print(\"\\nFrench question:\")\n",
    "print(\"Cosine similarity between html table and question:\",\n",
    "      cosine_similarity(html_embeddings, fr_question_embeddings))\n",
    "print(\"Cosine similarity between pipe table and question:\",\n",
    "        cosine_similarity(pipe_embeddings, fr_question_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two conclusions:\n",
    "- Be careful with languages\n",
    "- The HTML has a slightly better similarity score than the pipe table. The"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table summarization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try now to summarize the HTML and | tables to improves the similarity score between the question and the table content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_table(llm, prompt_text, extracted_table: str) -> str:\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "    # Summary chain\n",
    "    summarize_chain = (\n",
    "        {\n",
    "            \"extracted_table\": itemgetter(\"extracted_table\")\n",
    "        }\n",
    "        |\n",
    "        prompt\n",
    "        |\n",
    "        llm\n",
    "        |\n",
    "        StrOutputParser()\n",
    "    )\n",
    "    return summarize_chain.invoke(input={\"extracted_table\": extracted_table})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian.bastin/miniconda3/envs/.multi_venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:299: UserWarning: WARNING! kawargs is not default parameter.\n",
      "                    kawargs was transferred to model_kwargs.\n",
      "                    Please confirm that kawargs is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question = \"Summarize the table with keys informations.\"\n",
    "\n",
    "prompt_summarization = \"\"\"From the following HMTL or | separated table:\n",
    "    ----------\n",
    "    {extracted_table}\n",
    "    ----------\n",
    "    Summarize the table with keys informations.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_table_summary = summarize_table(\n",
    "    llm=GPT_4,\n",
    "    prompt_text=prompt_summarization,\n",
    "    extracted_table=pipe_table,\n",
    ")\n",
    "\n",
    "html_table_summary = summarize_table(\n",
    "    llm=GPT_4,\n",
    "    prompt_text=prompt_summarization,\n",
    "    extracted_table=html_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table provides information about different AI models from various providers along with their input and output prices per 1k and 1M tokens. \n",
      "\n",
      "1. The Azure OpenAI provides the GPT-4 (8K) model with an input price of $0.03000 per 1k tokens and $30.00 per 1M tokens. The output prices are $0.06000 per 1k tokens and $60.00 per 1M tokens.\n",
      "\n",
      "2. The GPT-4 Turbo model has an input price of $0.01000 per 1k tokens and $10.00 per 1M tokens. The output prices are $0.03000 per 1k tokens and $30.00 per 1M tokens.\n",
      "\n",
      "3. The GPT-3.5-turbo model has the lowest input price of $0.00050 per 1k tokens and $0.50 per 1M tokens. The output prices are $0.00150 per 1k tokens and $1.50 per 1M tokens.\n",
      "\n",
      "4. Google Vertex AI provides the Gemini Pro model where 1 token is approximately equal to 4 characters. The input price is $0.00100 per 1k tokens and $1.00 per 1M tokens. The output prices are $0.00200 per 1k tokens and $2.00 per 1M tokens.\n",
      "\n",
      "5. The PaLM 2 model has an input price of $0.00200 per 1k tokens and $2.00 per 1M tokens. Interestingly, the output prices are the same as the input prices.\n"
     ]
    }
   ],
   "source": [
    "print(pipe_table_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table provides information about the pricing of different AI models from providers such as Azure OpenAI and Google Vertex AI. \n",
      "\n",
      "1. Azure OpenAI offers three models: GPT-4 (8K), GPT-4 Turbo, and GPT-3.5-turbo. The input price per 1k tokens for these models are $0.03000, $0.01000, and $0.00050 respectively. The output prices per 1k tokens are $0.06000, $0.03000, and $0.00150 respectively. When considering 1M tokens, the input prices are $30.00, $10.00, and $0.50, and the output prices are $60.00, $30.00, and $1.50.\n",
      "\n",
      "2. Google Vertex AI, where 1 token is approximately equal to 4 characters, offers two models: Gemini Pro and PaLM 2. The input price per 1k tokens for these models are $0.00100 and $0.00200 respectively, and both have an output price per 1k tokens of $0.00200. For 1M tokens, the input prices are $1.00 and $2.00, and the output prices are $2.00 and $2.00.\n"
     ]
    }
   ],
   "source": [
    "print(html_table_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_pipe_table_embeddings = AZURE_ADA_002_EMBEDDINGS.embed_documents(\n",
    "    [pipe_table_summary])[0]\n",
    "\n",
    "summarized_html_embeddings = AZURE_ADA_002_EMBEDDINGS.embed_documents(\n",
    "    [html_table_summary])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English question\n",
      "Cosine similarity between summarized html table and question: 0.8293981621712595\n",
      "Cosine similarity between summarized pipe table and question: 0.8235538381337154\n",
      "\n",
      "French question:\n",
      "Cosine similarity between summarized html table and question: 0.7762218680702694\n",
      "Cosine similarity between summarized pipe table and question: 0.7657509307006923\n"
     ]
    }
   ],
   "source": [
    "# English question\n",
    "print(\"English question\")\n",
    "print(\"Cosine similarity between summarized html table and question:\",\n",
    "      cosine_similarity(summarized_html_embeddings, en_question_embeddings))\n",
    "print(\"Cosine similarity between summarized pipe table and question:\",\n",
    "      cosine_similarity(summarize_pipe_table_embeddings, en_question_embeddings))\n",
    "\n",
    "# French question\n",
    "print(\"\\nFrench question:\")\n",
    "print(\"Cosine similarity between summarized html table and question:\",\n",
    "      cosine_similarity(summarized_html_embeddings, fr_question_embeddings))\n",
    "print(\"Cosine similarity between summarized pipe table and question:\",\n",
    "      cosine_similarity(summarize_pipe_table_embeddings, fr_question_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a better cosine similarity score for a randomly chosen question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_question = \"How much does it cost to process 1M tokens with GPT-4 Turbo?\"\n",
    "en_question_embeddings = AZURE_ADA_002_EMBEDDINGS.embed_documents([en_question])[0]\n",
    "\n",
    "fr_question = \"Combien coÃ»te le traitement de 1M de tokens avec GPT-4 Turbo ?\"\n",
    "fr_question_embeddings = AZURE_ADA_002_EMBEDDINGS.embed_documents([fr_question])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without summarization \n",
      "\n",
      "English question\n",
      "Cosine similarity between html table and question: 0.8307020510808852\n",
      "Cosine similarity between pipe table and question: 0.8398822824210638\n",
      "\n",
      "French question:\n",
      "Cosine similarity between html table and question: 0.7975859989604802\n",
      "Cosine similarity between pipe table and question: 0.8040695385068106\n",
      "\n",
      "With summarization \n",
      "\n",
      "English question\n",
      "Cosine similarity between summarized html table and question: 0.8496684726885921\n",
      "Cosine similarity between summarized pipe table and question: 0.8477521058415244\n",
      "\n",
      "French question:\n",
      "Cosine similarity between summarized html table and question: 0.8211399793020073\n",
      "Cosine similarity between summarized pipe table and question: 0.8162567056870702\n"
     ]
    }
   ],
   "source": [
    "print(\"Without summarization \\n\")\n",
    "# English question\n",
    "print(\"English question\")\n",
    "print(\"Cosine similarity between html table and question:\",\n",
    "      cosine_similarity(html_embeddings, en_question_embeddings))\n",
    "print(\"Cosine similarity between pipe table and question:\",\n",
    "      cosine_similarity(pipe_embeddings, en_question_embeddings))\n",
    "\n",
    "# French question\n",
    "print(\"\\nFrench question:\")\n",
    "print(\"Cosine similarity between html table and question:\",\n",
    "      cosine_similarity(html_embeddings, fr_question_embeddings))\n",
    "print(\"Cosine similarity between pipe table and question:\",\n",
    "      cosine_similarity(pipe_embeddings, fr_question_embeddings))\n",
    "\n",
    "\n",
    "print(\"\\nWith summarization \\n\")\n",
    "# English question\n",
    "print(\"English question\")\n",
    "print(\"Cosine similarity between summarized html table and question:\",\n",
    "      cosine_similarity(summarized_html_embeddings, en_question_embeddings))\n",
    "print(\"Cosine similarity between summarized pipe table and question:\",\n",
    "      cosine_similarity(summarize_pipe_table_embeddings, en_question_embeddings))\n",
    "\n",
    "# French question\n",
    "print(\"\\nFrench question:\")\n",
    "print(\"Cosine similarity between summarized html table and question:\",\n",
    "      cosine_similarity(summarized_html_embeddings, fr_question_embeddings))\n",
    "print(\"Cosine similarity between summarized pipe table and question:\",\n",
    "      cosine_similarity(summarize_pipe_table_embeddings, fr_question_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The similarity improvement depends on the question asked but is still higher than the extracted table. \n",
    "- The summary is by definition a summary, it can helps the retriever to find the adequate chunks but may loose some information. For this reason we advice the developer to keep both the summary and the extracted table to provide a better semantic search. One should consider linking the summary to the original table and give only the orignal information to the context to avoid duplicated informations. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multim_venv",
   "language": "python",
   "name": "multim_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
